# InstructBLIP Prompt Tuning 實現

這個實現提供了使用 Prompt Tuning 方法來微調 InstructBLIP 模型進行 AI 圖像檢測的完整解決方案。

## 主要特點

### Prompt Tuning vs LoRA 的區別

**Prompt Tuning:**
- 只訓練少量的可學習提示參數（virtual tokens）
- 凍結整個預訓練模型的參數
- 參數效率極高，通常只有幾十KB到幾MB
- 適合快速適應新任務
- 學習率通常較高（0.01-0.1）

**LoRA:**
- 在模型的特定層添加低秩適配器
- 訓練更多參數但仍然高效
- 通常有更好的性能但需要更多資源
- 學習率較低（1e-4到1e-3）

## 檔案結構

```
src/training/
├── finetune_instructBLIP_prompt_tuning.py  # 主要訓練腳本
configs/
├── train_instructblip_prompt_tuning_config.yaml  # 配置文件
```

## 主要參數說明

### Prompt Tuning 參數

- `num_virtual_tokens`: 虛擬token數量
  - 範圍：10-100
  - 較少的tokens（10-20）：更快訓練，但可能性能有限
  - 較多的tokens（50-100）：更好性能，但訓練時間稍長

- `init_method`: 初始化方法
  - `"RANDOM"`: 隨機初始化（推薦）
  - `"TEXT"`: 使用文本初始化

- `learning_rate_prompt_tuning`: 學習率
  - 建議範圍：0.01-0.1
  - 比傳統微調高很多

## 使用方法

### 1. 安裝依賴

```bash
pip install torch transformers peft pillow pyyaml
```

### 2. 準備數據

確保數據結構如下：
```
data/
├── train/
│   ├── ai/       # AI生成的圖片
│   └── nature/   # 真實圖片
└── val/
    ├── ai/
    └── nature/
```

### 3. 修改配置文件

編輯 `configs/train_instructblip_prompt_tuning_config.yaml`：

```yaml
data:
  train_path: "你的訓練數據路徑"
  val_test_path: "你的驗證數據路徑"
  
model:
  prompt_tuning_params:
    num_virtual_tokens: 20  # 根據需要調整
    
training:
  learning_rate_prompt_tuning: 3.0e-2  # 根據需要調整
```

### 4. 開始訓練

```bash
python src/training/finetune_instructBLIP_prompt_tuning.py \
    --config configs/train_instructblip_prompt_tuning_config.yaml
```

### 5. 從檢查點恢復訓練

```bash
python src/training/finetune_instructBLIP_prompt_tuning.py \
    --config configs/train_instructblip_prompt_tuning_config.yaml \
    --resume results/instructblip_prompt_tuning/checkpoint-100
```

## 性能建議

### 超參數調優

1. **學習率調整**：
   - 開始時使用 0.03
   - 如果損失不下降，提高到 0.05-0.1
   - 如果訓練不穩定，降低到 0.01-0.02

2. **虛擬Token數量**：
   - 簡單任務：10-20個token
   - 複雜任務：30-50個token
   - 極複雜任務：50-100個token

3. **Batch Size**：
   - Prompt tuning可以使用較大的batch size
   - 建議：4-8（根據GPU記憶體調整）

### 訓練策略

1. **更多Epoch**：
   - Prompt tuning通常需要更多epoch才能收斂
   - 建議：10-20個epoch

2. **頻繁評估**：
   - 由於參數少，可以更頻繁地評估
   - 建議：每25-50步評估一次

3. **Early Stopping**：
   - 使用較長的patience防止過早停止
   - 建議：8-15個步驟的patience

## 監控和調試

### 重要日誌信息

訓練過程中注意以下日誌：

```
INFO - Prompt parameters found: X,XXX
INFO - Total trainable parameters: X,XXX / XX,XXX,XXX (0.XX%)
```

- 確保trainable parameters的比例很低（通常 < 1%）
- 如果比例太高，檢查prompt tuning配置

### 常見問題解決

1. **訓練不收斂**：
   - 增加虛擬token數量
   - 提高學習率
   - 增加訓練epoch數

2. **GPU記憶體不足**：
   - 減少batch size
   - 使用gradient accumulation
   - 啟用bfloat16混合精度

3. **過擬合**：
   - 減少虛擬token數量
   - 降低學習率
   - 增加驗證數據量

## 進階功能

### 1. 文本初始化

使用有意義的文本初始化prompt：

```yaml
model:
  prompt_tuning_params:
    num_virtual_tokens: 20
    init_method: "TEXT"
    init_text: "Analyze this image carefully to determine if it was generated by AI"
```

### 2. 多任務學習

可以修改代碼支持多個相關任務的prompt tuning：

```python
# 在配置中添加多個任務
tasks:
  - name: "ai_detection"
    prompt: "Is this image AI-generated?"
    num_virtual_tokens: 20
  - name: "quality_assessment"
    prompt: "Rate the quality of this image"
    num_virtual_tokens: 15
```

### 3. 動態prompt長度

根據任務複雜度動態調整prompt長度：

```python
def get_optimal_prompt_length(task_complexity):
    if task_complexity == "simple":
        return 10
    elif task_complexity == "medium":
        return 30
    else:
        return 50
```

## 性能基準

### 預期結果

在AI圖像檢測任務上，使用Prompt Tuning的預期性能：

- **訓練時間**：比LoRA快30-50%
- **記憶體使用**：比LoRA少60-80%
- **準確率**：通常比LoRA低2-5%，但仍能達到85-90%
- **參數量**：< 1% 的原模型參數

### 與其他方法的比較

| 方法 | 參數量 | 訓練時間 | 記憶體使用 | 預期準確率 |
|------|--------|----------|------------|------------|
| Full Fine-tuning | 100% | 最長 | 最高 | 90-95% |
| LoRA | 1-5% | 中等 | 中等 | 88-93% |
| Prompt Tuning | <1% | 最短 | 最低 | 85-90% |

## 實際應用建議

### 1. 快速原型開發

Prompt tuning適合：
- 快速驗證想法
- 資源受限的環境
- 需要快速部署的場景

### 2. 生產環境考慮

- **模型版本管理**：prompt embeddings很小，易於版本控制
- **A/B測試**：可以快速訓練多個版本進行比較
- **增量學習**：容易添加新的prompt用於新任務

### 3. 最佳實踐

1. **數據準備**：
   - 確保數據質量，因為prompt tuning對數據更敏感
   - 平衡各類別的樣本數量

2. **實驗管理**：
   - 記錄每次實驗的超參數設置
   - 使用統一的評估指標

3. **模型部署**：
   - 保存完整的模型配置
   - 測試推理性能

## 擴展和自定義

### 添加新的初始化方法

```python
def custom_prompt_initialization(tokenizer, num_virtual_tokens, custom_text):
    """自定義prompt初始化方法"""
    tokens = tokenizer(custom_text, return_tensors="pt")["input_ids"]
    if tokens.size(1) > num_virtual_tokens:
        tokens = tokens[:, :num_virtual_tokens]
    elif tokens.size(1) < num_virtual_tokens:
        padding = torch.zeros(1, num_virtual_tokens - tokens.size(1), dtype=torch.long)
        tokens = torch.cat([tokens, padding], dim=1)
    return tokens
```

### 自定義評估指標

```python
def compute_detailed_metrics(eval_preds):
    """計算更詳細的評估指標"""
    predictions, labels = eval_preds
    
    # 基本準確率
    accuracy = compute_accuracy_metrics(eval_preds)
    
    # 添加其他指標
    precision = compute_precision(predictions, labels)
    recall = compute_recall(predictions, labels)
    f1 = compute_f1(predictions, labels)
    
    return {
        "accuracy": accuracy["accuracy"],
        "precision": precision,
        "recall": recall,
        "f1": f1
    }
```

## 故障排除

### 常見錯誤及解決方案

1. **ImportError: No module named 'peft'**
   ```bash
   pip install peft
   ```

2. **CUDA out of memory**
   - 減少batch_size
   - 啟用gradient_checkpointing
   - 使用更小的模型

3. **No trainable parameters found**
   - 檢查prompt_tuning_config配置
   - 確保使用正確的finetune_method

4. **Loss不下降**
   - 提高學習率
   - 增加num_virtual_tokens
   - 檢查數據標籤是否正確

## 總結

Prompt Tuning提供了一種極其高效的模型適應方法，特別適合：

- 快速原型開發
- 資源受限的環境
- 需要頻繁更新的應用場景

雖然性能可能略低於全量微調或LoRA，但其極高的效率和靈活性使其成為很多場景下的最佳選擇。

通過合理的超參數設置和訓練策略，Prompt Tuning可以在AI圖像檢測任務上達到很好的效果，同時保持極低的計算和儲存成本。

#!/bin/bash

# InstructBLIP Prompt Tuning 完整使用範例
# 此腳本展示了從訓練到推理的完整流程

echo "=========================================="
echo "InstructBLIP Prompt Tuning 使用範例"
echo "=========================================="

# 設定環境變數
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
export CUDA_VISIBLE_DEVICES=0  # 設定使用的GPU

# 1. 準備工作目錄
echo "步驟 1: 準備工作目錄..."
mkdir -p results/instructblip_prompt_tuning
mkdir -p logs

# 2. 檢查配置文件
echo "步驟 2: 檢查配置文件..."
CONFIG_FILE="configs/train_instructblip_prompt_tuning_config.yaml"

if [ ! -f "$CONFIG_FILE" ]; then
    echo "錯誤: 配置文件 $CONFIG_FILE 不存在"
    echo "請確保配置文件已正確創建"
    exit 1
fi

echo "配置文件檢查通過: $CONFIG_FILE"

# 3. 開始訓練
echo "步驟 3: 開始 Prompt Tuning 訓練..."
echo "訓練日誌將保存到 logs/prompt_tuning_training.log"

python src/training/finetune_instructBLIP_prompt_tuning.py \
    --config $CONFIG_FILE \
    2>&1 | tee logs/prompt_tuning_training.log

# 檢查訓練是否成功
if [ $? -eq 0 ]; then
    echo "✓ 訓練完成成功!"
else
    echo "✗ 訓練失敗，請檢查日誌文件"
    exit 1
fi

# 4. 查找最佳檢查點
echo "步驟 4: 查找最佳檢查點..."
RESULTS_DIR="results/instructblip_prompt_tuning"
BEST_CHECKPOINT=$(find $RESULTS_DIR -name "checkpoint-*" -type d | sort -V | tail -1)

if [ -z "$BEST_CHECKPOINT" ]; then
    echo "警告: 未找到檢查點，使用最終模型進行推理"
    MODEL_PATH=$RESULTS_DIR
else
    echo "找到最佳檢查點: $BEST_CHECKPOINT"
    MODEL_PATH=$BEST_CHECKPOINT
fi

# 5. 準備測試圖片
echo "步驟 5: 準備測試圖片..."
TEST_IMAGE_DIR="test_images"

if [ ! -d "$TEST_IMAGE_DIR" ]; then
    echo "創建測試圖片目錄: $TEST_IMAGE_DIR"
    mkdir -p $TEST_IMAGE_DIR
    echo "請將測試圖片放入 $TEST_IMAGE_DIR 目錄中"
    echo "支援的格式: jpg、jpeg、png、webp"
fi

# 6. 運行推理（如果有測試圖片）
if [ "$(ls -A $TEST_IMAGE_DIR 2>/dev/null)" ]; then
    echo "步驟 6: 運行推理..."
    
    python inference_scripts/prompt_tuning_inference.py \
        --model_path $MODEL_PATH \
        --image_dir $TEST_IMAGE_DIR \
        --output_file results/inference_results.json \
        2>&1 | tee logs/inference.log
    
    if [ $? -eq 0 ]; then
        echo "✓ 推理完成!"
        echo "結果已保存到 results/inference_results.json"
    else
        echo "✗ 推理失敗，請檢查日誌"
    fi
else
    echo "步驟 6: 跳過推理（無測試圖片）"
    echo "要運行推理，請執行："
    echo "python inference_scripts/prompt_tuning_inference.py \\"
    echo "    --model_path $MODEL_PATH \\"
    echo "    --image_path your_image.jpg"
fi

# 7. 顯示結果摘要
echo "步驟 7: 顯示結果摘要..."

if [ -f "results/instructblip_prompt_tuning/eval_metrics.json" ]; then
    echo "=========================================="
    echo "訓練結果摘要:"
    echo "=========================================="
    python -c "
import json
with open('results/instructblip_prompt_tuning/eval_metrics.json', 'r') as f:
    metrics = json.load(f)
    print(f'驗證準確率: {metrics.get(\"eval_accuracy\", \"N/A\"):.4f}')
    print(f'驗證損失: {metrics.get(\"eval_loss\", \"N/A\"):.4f}')
    print(f'訓練步數: {metrics.get(\"step\", \"N/A\")}')
"
fi

# 8. 提供後續使用指南
echo "=========================================="
echo "後續使用指南:"
echo "=========================================="
echo "1. 單張圖片推理:"
echo "   python inference_scripts/prompt_tuning_inference.py \\"
echo "       --model_path $MODEL_PATH \\"
echo "       --image_path your_image.jpg"
echo ""
echo "2. 批量圖片推理:"
echo "   python inference_scripts/prompt_tuning_inference.py \\"
echo "       --model_path $MODEL_PATH \\"
echo "       --image_dir your_image_directory \\"
echo "       --output_file results.json"
echo ""
echo "3. 繼續訓練:"
echo "   python src/training/finetune_instructBLIP_prompt_tuning.py \\"
echo "       --config $CONFIG_FILE \\"
echo "       --resume $BEST_CHECKPOINT"
echo ""
echo "4. 調整超參數:"
echo "   編輯 $CONFIG_FILE 中的參數，特別是:"
echo "   - num_virtual_tokens (虛擬token數量)"
echo "   - learning_rate_prompt_tuning (學習率)"
echo "   - epochs (訓練輪數)"
echo ""

# 9. 清理和優化建議
echo "=========================================="
echo "優化建議:"
echo "=========================================="
echo "1. 如果準確率不理想:"
echo "   - 增加 num_virtual_tokens (20 -> 50)"
echo "   - 提高學習率 (0.03 -> 0.05)"
echo "   - 增加訓練epoch數"
echo ""
echo "2. 如果訓練不穩定:"
echo "   - 降低學習率 (0.03 -> 0.01)"
echo "   - 增加 warmup_steps"
echo "   - 減少 gradient_accumulation_steps"
echo ""
echo "3. 如果記憶體不足:"
echo "   - 減少 batch_size"
echo "   - 啟用 gradient_checkpointing"
echo "   - 使用更小的 num_virtual_tokens"

echo "=========================================="
echo "所有步驟完成!"
echo "=========================================="