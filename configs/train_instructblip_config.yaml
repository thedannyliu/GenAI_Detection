# configs/train_instructblip_config.yaml

# 資料設定 (Data Settings)
data:
  train_path: "/raid/dannyliu/dataset/GAI_Dataset/genimage/imagenet_ai_0419_sdv4/train"
  val_test_path: "/raid/dannyliu/dataset/GAI_Dataset/genimage/imagenet_ai_0419_sdv4/val"
  num_train_samples: 200                    # 稍微增加樣本數提升訓練效果
  num_val_samples: 100                      # 增加驗證樣本
  num_test_samples: 50
  seed: 42

# 模型設定 (Model Settings)
model:
  name_pretrained: "Salesforce/instructblip-vicuna-7b"
  finetune_method: "lora"
  lora_params:
    r: 16                                     # 稍微增加rank以獲得更好的表現
    alpha: 32                                 # 對應調整alpha (通常是r的2倍)
    dropout: 0.05                             # 降低dropout
    target_modules: ["q_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]

# 訓練設定 (Training Settings)
training:
  should_train: true
  epochs: 5                                   # 增加epoch數
  batch_size: 2                               # 稍微增加batch size (如果記憶體允許)
  eval_batch_size: 2                          # 對應增加評估batch size
  learning_rate_full: 5.0e-5
  learning_rate_lora: 1.0e-4                  # 稍微降低學習率提升穩定性
  warmup_steps: 100                           # 增加warmup steps
  weight_decay: 0.001                         # 降低weight decay
  max_target_token_length: 16
  prompt_config_idx: 0
  evaluation_strategy: "steps"
  eval_steps: 50                              # 調整評估頻率
  save_strategy: "steps"
  save_steps: 50                              # 調整保存頻率
  save_total_limit: 5                         # 保留更多檢查點
  early_stopping_patience: 5                 # 降低耐心值以避免過度訓練
  early_stopping_threshold: 0.001
  gradient_accumulation_steps: 4              # 降低梯度累積步數
  use_bfloat16: true
  gradient_checkpointing: false
  logging_steps: 10                           # 調整日誌頻率

# 輸出設定 (Output Settings)
output:
  base_results_dir_root: "results/instructblip_finetune"

# 環境設定 (Environment Settings)
environment:
  gpu_id: 2
  disable_wandb: true