# Configuration for zero-shot VLM evaluation

# General settings
output_dir: "results/zero_shot"

# Model settings
model:
  type: "clip"
  name: "openai/clip-vit-large-patch14"  # Using a larger CLIP model for better zero-shot performance
  mode: "zero-shot"

# Data settings
data:
  batch_size: 64  # Can use larger batches for inference
  
# Zero-shot settings
zero_shot:
  # Different prompt variants to try
  prompts:
    - "a real photograph captured by a camera"
    - "an artificial image generated by AI"
  
  # Alternative prompts
  # prompts:
  #   - "a genuine photograph of the real world"
  #   - "a computer-generated or AI-generated image"
  
  # Class-specific prompts (if use_class_names is true)
  # prompts:
  #   - "a real photo of a {}"
  #   - "an AI-generated image of a {}"
  
  use_class_names: false  # Set to true to incorporate ImageNet class names
  temperature: 1.0
  ensemble_method: "mean"  # How to combine results from multiple prompts: "mean" or "max"

# Evaluation settings
evaluation:
  metrics:
    - accuracy
    - auc
    - precision
    - recall
    - f1
  
  # For zero-shot, we might want to optimize the classification threshold
  optimize_threshold: true
  threshold_metric: "f1"
  
  # Output settings
  save_predictions: true
  predictions_file: "results/zero_shot/predictions.csv"
  
  # Analyze results by generator
  group_by_generator: true
  
  # Visualization
  generate_plots: true
  plot_dir: "results/zero_shot/figures"
  
  # Generate confusion matrices
  generate_confusion_matrix: true
  
  # Prompt comparison
  compare_prompts: true  # Compare performance across different prompt choices

# Logging settings
logging:
  experiment_name: "vlm_zero_shot"
  save_prompt_results: true 